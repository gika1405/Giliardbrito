{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "828813a1",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55cfc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp exec.preprocess_vits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cab3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import argparse\n",
    "from functools import reduce\n",
    "\n",
    "from uberduck_ml_dev.text.util import batch_clean_text, clean_text\n",
    "from uberduck_ml_dev.utils.utils import load_filepaths_and_text\n",
    "\n",
    "\n",
    "def batch(arr, batch_size):\n",
    "    for i in range(0, len(arr), batch_size):\n",
    "        yield arr[i : i + batch_size]\n",
    "\n",
    "\n",
    "def flatten(arr):\n",
    "    \"\"\"Flatten list of lists.\n",
    "\n",
    "    Only works for depth of 1.\n",
    "    \"\"\"\n",
    "    return reduce(lambda a, b: a + b, arr)\n",
    "\n",
    "\n",
    "try:\n",
    "    from nbdev.imports import IN_NOTEBOOK\n",
    "except:\n",
    "    IN_NOTEBOOK = False\n",
    "\n",
    "if __name__ == \"__main__\" and not IN_NOTEBOOK:\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--out_extension\", default=\"cleaned\")\n",
    "    parser.add_argument(\"--text_index\", default=1, type=int)\n",
    "    parser.add_argument(\n",
    "        \"--filelists\",\n",
    "        nargs=\"+\",\n",
    "        default=[\n",
    "            \"filelists/ljs_audio_text_val_filelist.txt\",\n",
    "            \"filelists/ljs_audio_text_test_filelist.txt\",\n",
    "        ],\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--text_cleaners\", nargs=\"+\", default=[\"english_cleaners_phonemizer\"]\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    for filelist in args.filelists:\n",
    "        print(\"START:\", filelist)\n",
    "        filepaths_and_text = load_filepaths_and_text(filelist)\n",
    "        text_batches = batch([fat[args.text_index] for fat in filepaths_and_text], 100)\n",
    "        cleaned_text_batch = flatten(\n",
    "            [batch_clean_text(batch, args.text_cleaners) for batch in text_batches]\n",
    "        )\n",
    "\n",
    "        for i in range(len(filepaths_and_text)):\n",
    "            filepaths_and_text[i][args.text_index] = cleaned_text_batch[i]\n",
    "\n",
    "        new_filelist = filelist + \".\" + args.out_extension\n",
    "        with open(new_filelist, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.writelines([\"|\".join(x) + \"\\n\" for x in filepaths_and_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e8ce93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
