# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/data.statistics.ipynb (unless otherwise specified).

__all__ = ['word_frequencies', 'create_wordcloud', 'count_frequency', 'pace_character', 'pace_phoneme',
           'get_sample_format', 'AbsoluteMetrics']

# Cell

from typing import List, Any, Dict, Union, Optional
from collections import Counter
import os

import librosa
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image, ImageOps
from pydub.utils import mediainfo_json
import seaborn as sns
from wordcloud import WordCloud, STOPWORDS
from wordfreq import word_frequency

from ..text.util import text_to_sequence

# Cell


def word_frequencies(text: str, language: str = "en") -> List[float]:
    """
    Calculate the frequency [0-1] which the words appear in the english language
    """
    freqs = []
    for word in text.split():
        freqs.append(word_frequency(word, language))
    return freqs


def create_wordcloud(text: str, output_file: str):
    """
    Creates and saves a wordcloud in the shape of a duck to the designated output file.
    """
    dir_path = os.path.dirname(os.path.realpath(__file__))

    mask = np.array(
        ImageOps.invert(
            Image.open(os.path.join(dir_path, "../assets/duck.png")).convert("RGB")
        )
    )
    wc = WordCloud(
        background_color="white",
        max_words=3000,
        mask=mask,
        contour_width=7,
        contour_color="steelblue",
    )
    frequency_dict = dict(Counter(text.lower().split()).most_common())
    for k in STOPWORDS:
        if k in frequency_dict.keys():
            frequency_dict.pop(k)

    wc.generate_from_frequencies(frequency_dict)
    wc.to_file(output_file)


def count_frequency(arr: List[Any]) -> Dict[Any, int]:
    """
    Calculates the frequency that a value appears in a list
    """
    return dict(Counter(arr).most_common())


def pace_character(
    text: str, audio: Union[str, np.ndarray], sr: Optional[int] = None
) -> float:
    """
    Calculates the number of characters in the text per second of the audio file. Audio can be a file path or an np array.
    """
    if isinstance(audio, str):
        audio, sr = librosa.load(audio, sr=None)
    else:
        assert sr, "Sampling rate must be provided if audio is np array"

    return len(text) / librosa.get_duration(audio, sr=sr)


def pace_phoneme(
    text: str, audio: Union[str, np.ndarray], sr: Optional[int] = None
) -> float:
    """
    Calculates the number of phonemes in the text per second of the audio. Audio can be a file path or an np array.
    """
    if isinstance(audio, str):
        audio, sr = librosa.load(audio, sr=None)
    else:
        assert sr, "Sampling rate must be provided if audio is np array"

    arpabet_seq = text_to_sequence(text, ["english_cleaners"], p_arpabet=1.0)
    return len(arpabet_seq) / librosa.get_duration(audio, sr=sr)


def get_sample_format(wav_file: str):
    """
    Get sample format of the .wav file: https://trac.ffmpeg.org/wiki/audio%20types
    """
    filename, file_extension = os.path.splitext(wav_file)
    assert file_extension == ".wav", ".wav file must be supplied"

    info = mediainfo_json(wav_file)
    audio_streams = [x for x in info["streams"] if x["codec_type"] == "audio"]
    return audio_streams[0].get("sample_fmt")


class AbsoluteMetrics:
    """This class loads and calculates the absolute metrics, MOSNet and SRMR"""

    def __init__(self, window_length: Optional[int] = None):
        # NOTE(zach): There are some problems installing speechmetrics via pip and it's not critical, so import inline to avoid issues in CI.
        import speechmetrics

        self.metrics = speechmetrics.load("absolute", window_length)

    def __call__(self, wav_file: str) -> Dict[str, float]:
        """
        Returns a Dict[str,float] with keys "mosnet" and "srmr"
        """
        filename, file_extension = os.path.splitext(wav_file)
        assert file_extension == ".wav", ".wav file must be supplied"

        return self.metrics(wav_file)